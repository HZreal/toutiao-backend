# 数据库主从分布式理论

## 1. 复制集与分布式
* 复制集（Replication）

  * 数据库中数据相同，起到备份作用

  * 高可用 High Available HA

* 分布式（Distribution）

  * 数据库中数据不同，共同组成完整的数据集合
    
  * 通常每个节点被称为一个分片（shard)

  * 高吞吐 High Throughput

* 复制集与分布式可以单独使用，也可以组合使用（即每个分片都组建一个复制集）

* 关于主（Master）从（Slave）

  * 这个概念是从使用的角度来阐述问题的

  * 主节点 -> 表示程序在这个节点上最先更新数据

  * 从节点 -> 表示这个节点的数据是要通过复制主节点而来

  * 复制集 可选 主从、主主、主主从从

  * 分布式 每个分片都是主，组合使用复制集的时候，复制集的是从

## 2. MySQL

### 1） 主从复制

#### 复制分成三步：

1. master将改变记录到二进制日志(binary log)中（这些记录叫做二进制日志事件，binary log events）
    * 在每个事务更新数据之前，master在二进制日志记录这些改变
    * 在事件写入二进制日志完成后，master通知存储引擎提交事务
2. slave将master的binary log events拷贝到它的中继日志(relay log)
    * slave开启一个I/O工作线程，与master进行连接(master也会启动一个工作线程进行处理)
    * 从master的二进制日志中读取事件，写入中继日志。若已经跟上master，它会睡眠并等待master产生新的事件
3. slave重做中继日志中的事件，将改变反映它自己的数据
    * slave开启一个SQL线程，从中继日志读取事件更新slave，中继日志通常会位于OS的缓存中，开销很小

#### 主从同步的意义
* 数据备份
* 配合使用读写分离，提高吞吐量(受限条件下提高读写速度)、高可用(某个节点宕机，其他节点依然可以)

#### 读写分离对事务是否有影响？或者说读写分离与事务是否冲突？
* 对于仅写操作包括开启事务和提交或回滚要在一台机器上执行，分散到多台master执行后数据库原生的单机事务就失效了。
* 对于事务中同时包含读写操作，与事务隔离级别设置有关
  * 如果事务隔离级别为read-uncommitted或者read-committed，读写分离没影响；
  一台机子的写操作事务，与另一台机子读操作事务，这两个事务的隔离级别可以做到read-uncommitted、read-committed
  * 如果隔离级别为repeatable-read、serializable，读写分离就有影响；
  在master的写操作事务，与slave上的读操作事务，这两个事务无法做到事务之间不受影响，因为在slave上欲读不受其他事物影响的数据，实际却读到已经被master写事务改变了的新数据，这与repeatable-read、serializable隔离级别性质相悖

事务隔离级别简介：
* read-uncommitted(读未提交)   一个事务进行了某个操作，不论是否提交，其他事物都能读到这个操作的结果，即想读取到新的数据
* read-committed(读已提交)     一个事务进行了某个操作，只有提交了，其他事物才能读到这个操作的结果，即想读取到新的数据
* repeatable-read(可重复度)    事务只能读到当前事物范围内的数据，并以当前数据作为参考，其他事物就算更新了数据也不在当前事物的可见范围内，即当前事物不受其他事物影响，不想读到其他事务更改的结果
* serializable(串行)          事务与事务采用串行先后执行，即它们之间互不影响

### 2）分库分表（sharding）

#### 分库分表前的问题

任何问题都是太大或者太小的问题，我们这里面对的数据量太大的问题。

如果你的系统处于快速发展时期，如果每天的订单流水都新增几十万，并且，订单表的查询效率明变慢时，就需要规划分库分表了。一般B+树索引高度是2~3层最佳，如果数据量千万级别，可能高度就变4层了，数据量就会明显变慢了

* 用户请求量太大

    因为单服务器TPS，内存，IO都是有限的。 解决方法：分散请求到多个服务器上； 其实用户请求和执行一个sql查询是本质是一样的，都是请求一个资源，只是用户请求还会经过网关，路由，http服务器等。

* 单库太大

    单个数据库处理能力有限；单库所在服务器上磁盘空间不足；单库上操作的IO瓶颈 解决方法：切分成更多更小的库

* 单表太大

    CRUD都成问题；索引膨胀，查询超时 解决方法：切分成多个数据集更小的表。

#### 分库分表的方式

1. 垂直分表

    基于列字段进行的。一般是表中的字段较多，将不常用的，数据较大，长度较长（比如text类型字段）的拆分到“扩展表“

2. 垂直分库

    * 针对的是一个系统中的不同业务进行拆分，比如用户User一个库，商品Producet一个库，订单Order一个库。 切分后，要放在多个服务器上

    * 数据库业务层面的拆分，和服务的“治理”，“降级”机制类似，也能对不同业务的数据分别的进行管理，维护，监控，扩展等    

    * 数据库本身属于“有状态”的，相对于Web和应用服务器来讲，是比较难实现“横向扩展”的

    * 数据库的连接资源比较宝贵且单机处理能力也有限，在高并发场景下，垂直分库一定程度上能够突破IO、连接数及单机硬件资源的瓶颈

3. 水平分表

    针对数据量巨大的单张表（比如订单表），按照某种规则（RANGE,HASH取模等），切分到多张表里面去。 但是这些表还是在同一个库中，所以库级别的数据库操作还是有IO瓶颈。不建议采用

4. 水平分库分表

    * 在水平分表的基础上，将单张表的数据切分到多个服务器上去，每个服务器具有相应的库与表，只是表中数据集合不同。 水平分库分表能够有效的缓解单机和单库的性能瓶颈和压力，突破IO、连接数、硬件资源等的瓶颈。
    * 水平分库分表切分规则
      * RANGE
      
        从0到10000一个表，10001到20000一个表；
      
      * HASH取模 离散化
      
        一个商场系统，一般都是将用户，订单作为主表，然后将和它们相关的作为附表，这样不会造成跨库事务之类的问题。 取用户id，然后hash取模，分配到不同的数据库上。
      
      * 地理区域
      
        比如按照华东，华南，华北这样来区分业务，七牛云应该就是如此。
      
      * 时间
      
        按照时间切分，就是将6个月前，甚至一年前的数据切出去放到另外的一张表，因为随着时间流逝，这些表的数据 被查询的概率变小，所以没必要和“热数据”放在一起，这个也是“冷热数据分离”。
      
#### 分库分表后面临的问题

* 事务支持

  分库分表后就需要使用分布式事务了。如果依赖数据库本身的分布式事务管理功能去执行事务，将付出高昂的性能代价； 如果由应用程序去协助控制，形成程序逻辑上的事务，又会造成编程方面的负担。

* 多库结果集合并（group by，order by）

* 跨库关联

  分库分表后，表之间的关联操作将受到限制，无法join位于不同分库的表，也无法join分表粒度不同的表， 结果原本一次查询能够完成的业务，可能需要多次查询才能完成。 粗略的解决方法： 全局表：基础数据，所有库都拷贝一份。 字段冗余：这样有些字段就不用join去查询了。 系统层组装：分别查询出所有，然后组装起来，较复杂。

* 排序问题

  跨节点的count,order by,group by以及聚合函数等问题：可以分别在各个节点上得到结果后在应用程序端进行合并

* 分页问题

  * 方案1：在个节点查到对应结果后，在代码端汇聚再分页。
  * 方案2：把分页交给前端，前端传来pageSize和pageNo，在各个数据库节点都执行分页，然后汇聚总数量前端。这样缺点就是会造成空查，如果分页需要排序，也不好搞。

* 分布式ID(下述)

  数据库被切分后，不能再依赖数据库自身的主键生成机制，最简单可以考虑UUID，或者使用雪花算法生成分布式ID


#### 分库分表方案产品

目前市面上的分库分表中间件
* 基于代理方式的有MySQL Proxy和Amoeba
* 基于Hibernate框架的是Hibernate Shards
* 基于jdbc的有当当sharding-jdbc
* 基于mybatis的类似maven插件式的有蘑菇街的蘑菇街TSharding
* 通过重写spring的ibatis template类的Cobar Client。

#### 相关文章

* 为什么要分库分表？

    https://mp.weixin.qq.com/s/b1r8OEfJ7iTMnN77TKJaYA

* 淘宝10年架构演进

    https://mp.weixin.qq.com/s/_0I099zeHqyzAvcz7KznpA

### 3）分布式ID（distributed ID）

#### 1. 方案选择

* uuid
  * UUID是通用唯一识别码
  * UUID是由128位二进制组成，一般转换成十六进制，然后用String表示
  
        550e8400-e29b-41d4-a716-446655440000
  
  * UUID的优点:
    * 通过本地生成，没有经过网络I/O，性能较快
    * 无序，无法预测他的生成顺序。(当然这个也是他的缺点之一)
  * UUID的缺点:
    * 128位二进制一般转换成36位的16进制，太长了只能用String存储，空间占用较多。
    * 不能生成递增有序的数字
    

* 数据库主键自增
  * 单独设置一个全局数据库，来记录主键值
  * 业务数据库分别设置不同的自增起始值和固定步长，如：
  
        第一台 start 1  step 9 
        第二台 start 2  step 9 
        第三台 start 3  step 9
  * 优点:
    * 简单方便，有序递增，方便排序和分页
  * 缺点:
    * 分库分表会带来问题，需要进行改造。
    * 并发性能不高，受限于数据库的性能。如步长为9则最多只能有9台机子
    * 简单递增容易被其他人猜测利用，比如你有一个用户服务用的递增，那么其他人可以根据分析注册的用户ID来得到当天你的服务有多少人注册，从而就能猜测出你这个服务当前的一个大概状况。
    * 数据库宕机服务不可用。如全局id数据库宕机
    

* Redis

  Redis中有两个命令Incr，IncrBy保证整型数据的递增，因为Redis是单线程的所以能保证原子性。
  * 优点：
    * 性能比数据库好，能满足有序递增。
  * 缺点：
    * 由于redis是内存的KV数据库，即使有AOF和RDB，但是依然会存在数据丢失，有可能会造成ID重复。
    * 依赖于redis，redis要是不稳定，会影响ID生成。


* 雪花算法-Snowflake

  Snowflake是Twitter提出来的一个算法，其目的是生成一个64bit的整数，详细如下

#### 2. 雪花算法

* 64位划分的标准
  * 1bit:一般是符号位，不做处理
  * 41bit:用来记录时间戳，这里可以记录69年，如果设置好起始时间比如今年是2018年，那么可以用到2089年，到时候怎么办？要是这个系统能用69年，我相信这个系统早都重构了好多次了。
  * 10bit:10bit用来记录机器ID，总共可以记录1024台机器，一般用前5位代表数据中心，后面5位是某个数据中心的机器ID
  * 12bit:循环位，用来对同一个毫秒之内产生不同的ID，12位可以最多记录4095个，也就是在同一个机器同一毫秒最多记录4095个，多余的需要进行等待下毫秒


* 基于上述机制，可以根据不同业务的具体场景来划分
  * 比如这样一个业务场景：
    * 服务目前QPS10万，预计几年之内会发展到百万。
    * 当前机器三地部署，上海，北京，深圳都有。
    * 当前机器10台左右，预计未来会增加至百台。
  * 分析：
    * 合理划分62bit
    * QPS几年之内会发展到百万，那么每毫秒就是千级的请求，目前10台机器那么每台机器承担百级的请求
    * 为了保证扩展，后面的循环位可以限制到1024，也就是2^10，那么循环位10位就足够了
  * 最终划分方案：
    * 机器三地部署我们可以用3bit总共8来表示机房位置
    * 当前的机器10台，为了保证扩展到百台那么可以用7bit 128来表示
    * 时间位依然是41bit
    * 还剩下2bit可以用来进行扩展。


* 时钟回拨

  因为机器的原因会发生时间回拨，我们的雪花算法是强依赖我们的时间的，如果时间发生回拨，有可能会生成重复的ID，在我们上面的nextId中我们用当前时间和上一次的时间进行判断，如果当前时间小于上一次的时间那么肯定是发生了回拨，算法会直接抛出异常(可以让创建id操作阻塞直到时间校准完成，也可以不校准，得到的id依然趋势递增).


* 雪花算法源码(采用scala描述)

  https://github.com/twitter-archive/snowflake/blob/snowflake-2010/src/main/scala/com/twitter/service/snowflake/IdWorker.scala


### 4）数据库优化（DB Optimization）

doc: https://dev.mysql.com/doc/refman/8.0/en/optimization.html

#### 索引

* 索引机制

   创建索引文件时维护了一个B+树，能更快的比较查询，定位到记录的位置

* 索引优劣
   * 极大提高查询速度
   * 由于增删改时需要维护索引文件，会增加开销，速度也会降低。

#### SQL查询优化

* 避免全表扫描，应考虑在 where 及 order by 经常涉及的列上建立索引；
* 查询时使用select明确指明所要查询的字段，避免使用select *的操作；
* SQL语句尽量大写，减少数据库在解析sql语句时会先转换成大写的过程；
* 避免在 where 子句中使用 != 或 <> 操作符，只有对以下操作符才能利用索引：<，<=，=，>，>=，BETWEEN，IN，以及某些时候的LIKE；
* 避免使用模糊查询，会导致全表扫描，若要提高效率，可以考虑全文检索；
* 遵循最左原则，在where子句有多个查询条件时，把创建了索引的字段放在前面；若多个字段经常一起作为条件，可为它们创建复合索引，且查询时字段的顺序与创建索引时的顺序保持一致(否则无法理由符合索引)；
* 能使用关联查询解决的尽量不要使用子查询；
* 能不使用关联查询的尽量不要使用关联查询；
* 不需要获取全表数据的时候，不要查询全表数据，使用LIMIT来限制数据；


#### 数据库优化

* 在进行表设计时，可适度增加冗余字段(反范式设计)，减少JOIN操作；
* 多字段表可以进行垂直分表优化，多数据表可以进行水平分表优化；
* 选择恰当的数据类型，如整型的选择；
* 对于强调快速读取又无需关心事务的操作，可以考虑使用MyISAM数据库引擎；
* 对频繁作为查询条件的字段创建索引；唯一性太差的字段(如性别)就算频繁地作为查询条件也不适合创建索引；更新非常频繁的字段不适合创建索引；
* 编写SQL时使用上面的方式对SQL语句进行优化；
* 使用慢查询工具找出效率低下的SQL语句进行优化；
* 构建缓存，减少数据库磁盘操作；
* 可以考虑结合使用内在型数据库，如Redis，进行混合存储。比如统计的冗余信息从mysql迁出到redis









